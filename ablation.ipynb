{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13df4e70-e90b-4525-ba56-9d48092af7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Files\"\"\"\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "files_data = pd.read_csv('../../../../../ds004504/participants.tsv', sep=\"\\t\")\n",
    "\n",
    "files = []\n",
    "for file in glob.glob(\"../../../../../ds004504/derivatives/*/*/*.set\"):\n",
    "    files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e83f84-0dc3-43dc-8ae8-76a3cf2363ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"build data features and connectivity bands, \n",
    "Here the duration of each epoch is 30 sec and\n",
    "the calculated connectivities\"\"\"\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from read_data import build_data\n",
    "\n",
    "SAVED_DATA = True\n",
    "\n",
    "if SAVED_DATA:\n",
    "    #with open('saved_files/all_boxcox_30.pkl', 'rb') as fp:\n",
    "    #    all_boxcox = pickle.load(fp)\n",
    "    with open('saved_files/all_X_bands_30.pkl', 'rb') as fp:\n",
    "        all_X = pickle.load(fp)\n",
    "    with open('saved_files/feat_30.pkl', 'rb') as fp:\n",
    "        all_feat = pickle.load(fp)\n",
    "    with open('saved_files/all_graphs_30.pkl', 'rb') as fp:\n",
    "        all_graphs= pickle.load(fp)\n",
    "    with open('saved_files/all_y_30.pkl', 'rb') as fp:\n",
    "        all_y = pickle.load(fp)\n",
    "    with open('saved_files/MMSE_30.pkl', 'rb') as fp:\n",
    "        MMSE = pickle.load(fp)\n",
    "\n",
    "else:\n",
    "    all_X, all_graphs, all_y, ch_names = build_data(files, size=30, \n",
    "                                                files_data=files_data,\n",
    "                                                cal_conn=\"all\", \n",
    "                                                raw_eeg=True, \n",
    "                                                bands=True, \n",
    "                                                data_used=\"dem\")\n",
    "    all_feat = cal_features(all_X)\n",
    "    MMSE = {}\n",
    "    for file in files:\n",
    "        MMSE[file] = get_MMSE(file)\n",
    "    \n",
    "    #all_boxcox = boxcox_dict(all_X, files)\n",
    "    for k, v in all_X.items():\n",
    "        all_X[k] = np.float16(v)\n",
    "    for k, v in all_graphs.items():\n",
    "        all_graphs[k] = np.float16(v) \n",
    "    #for k, v in all_boxcox.items():\n",
    "    #    all_boxcox[k] = np.float16(v) \n",
    "    with open('saved_files/feat_30.pkl', 'wb') as fp:\n",
    "        pickle.dump(all_feat, fp)\n",
    "    with open('saved_files/all_X_bands_30.pkl', 'wb') as fp:\n",
    "        pickle.dump(all_X, fp)\n",
    "    with open('saved_files/all_graphs_30.pkl', 'wb') as fp:\n",
    "        pickle.dump(all_graphs, fp)\n",
    "    with open('saved_files/all_y_30.pkl', 'wb') as fp:\n",
    "        pickle.dump(all_y, fp)\n",
    "    with open('saved_files/MMSE_30.pkl', 'wb') as fp:\n",
    "        pickle.dump(MMSE, fp)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4d17c46-d958-4078-bad4-ea754bd16153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD Prediction\n",
      "Coherence\n",
      "Accuracy: 0.7660956881275842\n",
      "Sensitivity: 0.7665995975855131\n",
      "Specificity: 0.765379113018598\n",
      "Precision: 0.8228941684665226\n",
      "F1: 0.7937500000000001\n",
      "==================\n",
      "PLI\n",
      "Accuracy: 0.7359716479621973\n",
      "Sensitivity: 0.7257304429783223\n",
      "Specificity: 0.7531645569620253\n",
      "Precision: 0.8315334773218143\n",
      "F1: 0.7750377453447409\n",
      "==================\n",
      "PLV\n",
      "Accuracy: 0.7371529828706438\n",
      "Sensitivity: 0.7836084905660378\n",
      "Specificity: 0.6905325443786983\n",
      "Precision: 0.7176025917926566\n",
      "F1: 0.7491544532130778\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Ablation study for trying different connectivities alone (Coherence, PLI, PLV)\"\"\"   \n",
    "\n",
    "import torch, gc\n",
    "from torch_geometric.loader import DataLoader\n",
    "import random\n",
    "from sklearn.model_selection import KFold    \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from utils import build_pyg_dl\n",
    "from read_data import stack_arrays\n",
    "from train import trainer, train_test_split_subjects, predict\n",
    "from evaluate import cal_accuracy, cal_accuracy_loso\n",
    "from models.ADgraph import ADGraph\n",
    "from evaluate import avg_accuracy\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "NUM_EDGES = 5 # 5 frequency bands in coh or plv, pli\n",
    "NUM_CONNS= 3\n",
    "NUM_CHANNELS= 19 # number of used EEG channels\n",
    "DEVICE = \"cpu\" # if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_EPOCHS = 35 \n",
    "TASK = \"AD\"\n",
    "NUM_TIMEPOINTS = None\n",
    "NUM_CLASSES = 2\n",
    "NUM_OUT_FEAT = 64\n",
    "SKIP_LABEL = 2 # 0:C, 1:AD, 2:FTD\n",
    "SEED = 2025\n",
    "\n",
    "results = {}\n",
    "task_files = []\n",
    "for file in files:\n",
    "    if all_y[file][0] ==  1 or all_y[file][0] ==  0:\n",
    "        task_files.append(file)\n",
    "\n",
    "\n",
    "for conn_idx in range(3):\n",
    "    num_kfolds = int(len(task_files))\n",
    "    num_runs = num_kfolds\n",
    "    \n",
    "    kf = KFold(n_splits=num_kfolds, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    all_cm = {}\n",
    "    AD_saved_models = []\n",
    "    AD_saved_iters = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(task_files):\n",
    "        train_files = [task_files[i] for i in train_idx]\n",
    "        val_files = [task_files[i] for i in val_idx]\n",
    "        train_X2 = [all_feat[i] for i in train_files]\n",
    "        val_X2 = [all_feat[i] for i in val_files]\n",
    "        train_graphs = [all_graphs[i] for i in train_files]\n",
    "        val_graphs = [all_graphs[i] for i in val_files]\n",
    "        train_y = [all_y[i] for i in train_files]\n",
    "        val_y = [all_y[i] for i in val_files]\n",
    "    \n",
    "        print(\"LOSO Subject:\", val_files)\n",
    "        \n",
    "        # Stacks window arrays\n",
    "        train_X, train_graphs, train_y = stack_arrays(train_X2, train_graphs, train_y, task=TASK)\n",
    "        val_X, val_graphs, val_y = stack_arrays(val_X2, val_graphs, val_y, task=TASK)\n",
    "        \n",
    "        # take only one connectivity with all frequency bands\n",
    "        val_graphs = val_graphs.reshape(val_graphs.shape[0], 19, 19, 5, 3)[:, :, :, :, conn_idx].reshape(val_graphs.shape[0], 19, 19, 5)\n",
    "        train_graphs = train_graphs.reshape(train_graphs.shape[0], 19, 19, 5, 3)[:, :, :, :, conn_idx].reshape(train_graphs.shape[0], 19, 19, 5)\n",
    "        \n",
    "        #ohe\n",
    "        ohe = OneHotEncoder()\n",
    "        train_y = ohe.fit_transform(train_y).toarray()\n",
    "        val_y = ohe.transform(val_y).toarray()\n",
    "        \n",
    "        # build pyg dataloader\n",
    "        train_dataset = [build_pyg_dl(x, g, y, NUM_EDGES, DEVICE) for x, g, y in zip(train_X, train_graphs, train_y)]\n",
    "        val_dataset = [build_pyg_dl(x, g, y, NUM_EDGES, DEVICE) for x, g, y in zip(val_X, val_graphs, val_y)]\n",
    "        train_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_iter = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # create model\n",
    "        torch.manual_seed(SEED)\n",
    "        model = ADGraph(num_nodes=NUM_CHANNELS, \n",
    "                        num_out_feat=NUM_OUT_FEAT, \n",
    "                        num_classes=NUM_CLASSES, \n",
    "                        device=DEVICE, \n",
    "                        num_edges=NUM_EDGES, \n",
    "                        num_conns= NUM_CONNS,\n",
    "                        timepoints=NUM_TIMEPOINTS, \n",
    "                        operator = \"TransformerConv\",\n",
    "                        num_signals=NUM_SIGNALS).to(DEVICE)\n",
    "        \n",
    "        # training\n",
    "        model, _, _ = trainer(NUM_EPOCHS, model, train_iter, val_iter, lr=0.00001)\n",
    "        ytrue, ypreds = predict(model, val_iter)\n",
    "        val_acc = cal_accuracy_loso(ytrue, ypreds)\n",
    "        all_cm[val_files[0]] = val_acc[1]\n",
    "        print(\"LOSO Accuracy: \", val_acc)\n",
    "        AD_saved_models.append(model)\n",
    "        AD_saved_iters.append(val_iter)\n",
    "        del train_X\n",
    "        del val_X\n",
    "\n",
    "    results[conn_idx] = avg_accuracy(all_cm, all_y)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "print(\"AD Prediction\")\n",
    "conns = [\"Coherence\", \"PLI\", \"PLV\"]\n",
    "idx = 0\n",
    "for k, v in results.items():\n",
    "    acc, sen, spec, prec, f1 = v\n",
    "    print(conns[idx])\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Sensitivity:\", sen)\n",
    "    print(\"Specificity:\", spec)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"==================\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db8b39a8-ac03-4441-afe0-61ab46215832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Coherence, PLV, PLI\n",
      "Accuracy: 0.7141169521559362\n",
      "Sensitivity: 0.7299687825182102\n",
      "Specificity: 0.6933060109289617\n",
      "Precision: 0.7575593952483801\n",
      "F1: 0.7435082140964494\n"
     ]
    }
   ],
   "source": [
    "\"\"\"performances of using all combined connectivities: Coherence, PLI, PLV averaged over frequency bands\"\"\"\n",
    "  \n",
    "NUM_EDGES = 3 # coh, plv, pli averaged over all frequency bands\n",
    "\n",
    "num_kfolds = int(len(task_files))\n",
    "num_runs = num_kfolds\n",
    "\n",
    "kf = KFold(n_splits=num_kfolds, shuffle=True, random_state=SEED)\n",
    "\n",
    "all_cm = {}\n",
    "AD_saved_models = []\n",
    "AD_saved_iters = []\n",
    "\n",
    "\n",
    "for train_idx, val_idx in kf.split(task_files):\n",
    "    train_files = [task_files[i] for i in train_idx]\n",
    "    val_files = [task_files[i] for i in val_idx]\n",
    "    train_X2 = [all_feat[i] for i in train_files]\n",
    "    val_X2 = [all_feat[i] for i in val_files]\n",
    "    train_graphs = [all_graphs[i] for i in train_files]\n",
    "    val_graphs = [all_graphs[i] for i in val_files]\n",
    "    train_y = [all_y[i] for i in train_files]\n",
    "    val_y = [all_y[i] for i in val_files]\n",
    "\n",
    "    print(\"LOSO Subject:\", val_files)\n",
    "    \n",
    "    # Stacks window arrays\n",
    "    train_X, train_graphs, train_y = stack_arrays(train_X2, train_graphs, train_y, task=TASK)\n",
    "    val_X, val_graphs, val_y = stack_arrays(val_X2, val_graphs, val_y, task=TASK)\n",
    "    \n",
    "    # take only one connectivity with all frequency bands\n",
    "    val_graphs = np.mean(val_graphs.reshape(val_graphs.shape[0], 19, 19, 5, 3), \n",
    "                         -2).reshape(val_graphs.shape[0], 19, 19, 3)\n",
    "    train_graphs = np.mean(train_graphs.reshape(train_graphs.shape[0], 19, 19, 5, 3), \n",
    "                           -2).reshape(train_graphs.shape[0], 19, 19, 3)\n",
    "    \n",
    "    #ohe\n",
    "    ohe = OneHotEncoder()\n",
    "    train_y = ohe.fit_transform(train_y).toarray()\n",
    "    val_y = ohe.transform(val_y).toarray()\n",
    "    \n",
    "    # build pyg dataloader\n",
    "    train_dataset = [build_pyg_dl(x, g, y, NUM_EDGES, DEVICE) for x, g, y in zip(train_X, train_graphs, train_y)]\n",
    "    val_dataset = [build_pyg_dl(x, g, y, NUM_EDGES, DEVICE) for x, g, y in zip(val_X, val_graphs, val_y)]\n",
    "    train_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_iter = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # create model\n",
    "    torch.manual_seed(SEED)\n",
    "    model = ADGraph(num_nodes=NUM_CHANNELS, \n",
    "                    num_out_feat=NUM_OUT_FEAT, \n",
    "                    num_classes=NUM_CLASSES, \n",
    "                    device=DEVICE, \n",
    "                    num_edges=NUM_EDGES, \n",
    "                    num_conns= NUM_CONNS,\n",
    "                    timepoints=NUM_TIMEPOINTS,\n",
    "                    operator = \"TransformerConv\",\n",
    "                    num_signals=NUM_SIGNALS).to(DEVICE)\n",
    "    \n",
    "    # training\n",
    "    model, _, _ = trainer(NUM_EPOCHS, model, train_iter, val_iter, lr=0.00001)\n",
    "    ytrue, ypreds = predict(model, val_iter)\n",
    "    val_acc = cal_accuracy_loso(ytrue, ypreds)\n",
    "    all_cm[val_files[0]] = val_acc[1]\n",
    "    print(\"LOSO Accuracy: \", val_acc)\n",
    "    AD_saved_models.append(model)\n",
    "    AD_saved_iters.append(val_iter)\n",
    "    del train_X\n",
    "    del val_X\n",
    "\n",
    "clear_output()\n",
    "results = {}\n",
    "\n",
    "results[\"average\"] = avg_accuracy(all_cm, all_y)\n",
    "\n",
    "for k, v in results.items():\n",
    "    acc, sen, spec, prec, f1 = v\n",
    "    print(\"Using Coherence, PLV, PLI\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Sensitivity:\", sen)\n",
    "    print(\"Specificity:\", spec)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"F1:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
